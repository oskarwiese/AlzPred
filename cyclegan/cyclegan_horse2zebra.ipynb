{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HORSE2ZEBRA BACKUP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "import torch\r\n",
    "import torchvision\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torchvision.datasets as datasets\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "import torchvision.transforms as transforms\r\n",
    "from IPython import display\r\n",
    "import matplotlib.pylab as plt\r\n",
    "import ipywidgets"
   ],
   "outputs": [],
   "metadata": {
    "id": "47nzjxI_CGX3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Horse2Zebra data"
   ],
   "metadata": {
    "id": "BGByM6KPlrwJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from google.colab import drive\r\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IaBeL5J_lvdz",
    "outputId": "2195641b-33f3-45b0-d7d6-e726d7cb93d5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#batch_size = 64\n",
    "batch_size = 5\n",
    "color_channels = 3\n",
    "image_size = (256,256)\n",
    "\n",
    "dataroot = r\"/content/drive/MyDrive/bachelor - cyclegan/horse2zebra/train/A/\"\n",
    "dataset_horse_train = datasets.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0, 0, 0), (1, 1, 1)),\n",
    "                              ]))\n",
    "dataloader_train_horse = torch.utils.data.DataLoader(dataset_horse_train, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers = 1)\n",
    "\n",
    "dataroot = r\"/content/drive/MyDrive/bachelor - cyclegan/horse2zebra/test/A/\"\n",
    "dataset_horse_test = datasets.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0, 0, 0), (1, 1, 1)),\n",
    "                              ]))\n",
    "dataloader_test_horse = torch.utils.data.DataLoader(dataset_horse_test, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=1)\n",
    "\n",
    "dataroot = r\"/content/drive/MyDrive/bachelor - cyclegan/horse2zebra/train/B/\"\n",
    "dataset_zebra_train = datasets.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0, 0, 0), (1, 1, 1)),\n",
    "                              ]))\n",
    "dataloader_zebra_train = torch.utils.data.DataLoader(dataset_zebra_train, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers = 1)\n",
    "\n",
    "dataroot = r\"/content/drive/MyDrive/bachelor - cyclegan/horse2zebra/test/B/\"\n",
    "dataset_zebra_test = datasets.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0, 0, 0), (1, 1, 1)),\n",
    "                              ]))\n",
    "dataloader_zebra_test = torch.utils.data.DataLoader(dataset_zebra_test, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers = 1)"
   ],
   "outputs": [],
   "metadata": {
    "id": "eM0FnWhwzbDN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The code will run on GPU.\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NmG1sJLICR5M",
    "outputId": "10bf1f0f-bb0c-4b09-f68e-40ba38196075"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Generator"
   ],
   "metadata": {
    "id": "6Nkoh0umC65N"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def conv_norm_act(in_dim, out_dim, kernel_size, stride, padding=0,\n",
    "                  norm=nn.BatchNorm2d, relu=nn.ReLU):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_dim, out_dim, kernel_size, stride, padding, bias=False),\n",
    "        norm(out_dim),\n",
    "        relu())\n",
    "\n",
    "\n",
    "def dconv_norm_act(in_dim, out_dim, kernel_size, stride, padding=0,\n",
    "                   output_padding=0, norm=nn.BatchNorm2d, relu=nn.ReLU):\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_dim, out_dim, kernel_size, stride,\n",
    "                           padding, output_padding, bias=False),\n",
    "        norm(out_dim),\n",
    "        relu())\n",
    "    \n",
    "class ResiduleBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(ResiduleBlock, self).__init__()\n",
    "\n",
    "        conv_bn_relu = conv_norm_act\n",
    "\n",
    "        self.ls = nn.Sequential(nn.ReflectionPad2d(1),\n",
    "                                conv_bn_relu(in_dim, out_dim, 3, 1),\n",
    "                                nn.ReflectionPad2d(1),\n",
    "                                nn.Conv2d(out_dim, out_dim, 3, 1),\n",
    "                                nn.BatchNorm2d(out_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.ls(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        conv_bn_relu = conv_norm_act\n",
    "        dconv_bn_relu = dconv_norm_act\n",
    "\n",
    "        self.ls = nn.Sequential(nn.ReflectionPad2d(3),\n",
    "                                conv_bn_relu(3, dim * 1, 7, 1),\n",
    "                                conv_bn_relu(dim * 1, dim * 2, 3, 2, 1),\n",
    "                                conv_bn_relu(dim * 2, dim * 4, 3, 2, 1),\n",
    "                                ResiduleBlock(dim * 4, dim * 4),\n",
    "                                ResiduleBlock(dim * 4, dim * 4),\n",
    "                                ResiduleBlock(dim * 4, dim * 4),\n",
    "                                ResiduleBlock(dim * 4, dim * 4),\n",
    "                                ResiduleBlock(dim * 4, dim * 4),\n",
    "                                ResiduleBlock(dim * 4, dim * 4),\n",
    "                                ResiduleBlock(dim * 4, dim * 4),\n",
    "                                ResiduleBlock(dim * 4, dim * 4),\n",
    "                                ResiduleBlock(dim * 4, dim * 4),\n",
    "                                dconv_bn_relu(dim * 4, dim * 2, 3, 2, 1, 1),\n",
    "                                dconv_bn_relu(dim * 2, dim * 1, 3, 2, 1, 1),\n",
    "                                nn.ReflectionPad2d(3),\n",
    "                                nn.Conv2d(dim, 3, 7, 1),\n",
    "                                nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ls(x)\n",
    "\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.model = nn.Sequential(\n",
    "#           nn.Linear(100,2848),\n",
    "#           nn.BatchNorm1d(2848),\n",
    "#           nn.LeakyReLU(0.2),\n",
    "#           nn.Linear(2848,2848),\n",
    "#           nn.BatchNorm1d(2848),\n",
    "#           nn.LeakyReLU(0.2),\n",
    "#           nn.Linear(2848,2848),\n",
    "#           nn.BatchNorm1d(2848),\n",
    "#           nn.LeakyReLU(0.2),\n",
    "#           nn.Linear(2848,2848),\n",
    "#           nn.BatchNorm1d(2848),\n",
    "#           nn.LeakyReLU(0.2),\n",
    "#           nn.Linear(2848,784),\n",
    "#           nn.Tanh()\n",
    "#         )\n",
    "\n",
    "        \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         x = self.model(x)\n",
    "#         x = x.view(x.size(0), 1, 28, 28)\n",
    "#         return x"
   ],
   "outputs": [],
   "metadata": {
    "id": "D4GrfzsYDAvR"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# norm_layer = nn.InstanceNorm2d\n",
    "# class ResBlock(nn.Module):\n",
    "#     def __init__(self, f):\n",
    "#         super(ResBlock, self).__init__()\n",
    "#         self.conv = nn.Sequential(nn.Conv2d(f, f, 3, 1, 1), norm_layer(f), nn.ReLU(),\n",
    "#                                   nn.Conv2d(f, f, 3, 1, 1))\n",
    "#         self.norm = norm_layer(f)\n",
    "#     def forward(self, x):\n",
    "#         return F.relu(self.norm(self.conv(x)+x))\n",
    "\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, f=64, blocks=9):\n",
    "#         super(Generator, self).__init__()\n",
    "#         layers = [nn.ReflectionPad2d(3),\n",
    "#                   nn.Conv2d(  3,   f, 7, 1, 0), norm_layer(  f), nn.ReLU(True),\n",
    "#                   nn.Conv2d(  f, 2*f, 3, 2, 1), norm_layer(2*f), nn.ReLU(True),\n",
    "#                   nn.Conv2d(2*f, 4*f, 3, 2, 1), norm_layer(4*f), nn.ReLU(True)]\n",
    "#         for i in range(int(blocks)):\n",
    "#             layers.append(ResBlock(4*f))\n",
    "#         layers.extend([\n",
    "#                 nn.ConvTranspose2d(4*f, 4*2*f, 3, 1, 1), nn.PixelShuffle(2), norm_layer(2*f), nn.ReLU(True),\n",
    "#                 nn.ConvTranspose2d(2*f,   4*f, 3, 1, 1), nn.PixelShuffle(2), norm_layer(  f), nn.ReLU(True),\n",
    "#                 nn.ReflectionPad2d(3), nn.Conv2d(f, 3, 7, 1, 0),\n",
    "#                 nn.Tanh()])\n",
    "#         self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         return self.conv(x)"
   ],
   "outputs": [],
   "metadata": {
    "id": "_1iL1ClXgOjn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Discriminator"
   ],
   "metadata": {
    "id": "QShX15bkDCh2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "          nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
    "          nn.Dropout(p=0.3),\n",
    "          nn.LeakyReLU(0.2),\n",
    "          nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "          nn.Dropout(p=0.3),\n",
    "          nn.LeakyReLU(0.2),\n",
    "          nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "          nn.Dropout(p=0.3),\n",
    "          nn.LeakyReLU(0.2),\n",
    "          nn.Conv2d(256, 512, 4, 1, 1, bias=False),\n",
    "          nn.Dropout(p=0.3),\n",
    "          nn.LeakyReLU(0.2),\n",
    "          nn.Conv2d(512, 4, 4, 1, 1, bias=False),\n",
    "          nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.model(x)\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {
    "id": "zZzBFUqEDEAe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train loop"
   ],
   "metadata": {
    "id": "tqKdKwSyDE3D"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#Initialize networks\n",
    "d_a = Discriminator().to(device)\n",
    "d_b = Discriminator().to(device)\n",
    "g_ab = Generator().to(device)\n",
    "g_ba = Generator().to(device)\n",
    "d_a_opt = torch.optim.Adam(d_a.parameters(), 0.0004, (0.5, 0.999))\n",
    "d_b_opt = torch.optim.Adam(d_b.parameters(), 0.0004, (0.5, 0.999))\n",
    "g_ab_opt = torch.optim.Adam(g_ab.parameters(), 0.0001, (0.5, 0.999))\n",
    "g_ba_opt = torch.optim.Adam(g_ba.parameters(), 0.0001, (0.5, 0.999))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "subplots = [plt.subplot(2, 6, k+1) for k in range(12)]\n",
    "num_epochs = 10\n",
    "discriminator_final_layer = torch.sigmoid\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for minibatch_no, ((a, target_a), (b, target_b)) in enumerate(zip(dataloader_train_horse, dataloader_zebra_train)):\n",
    "        \n",
    "\n",
    "        # It is probably necessary to call zero_grad and detach for some of these models. I do not know which ones yet.\n",
    "        \n",
    "        d_a.zero_grad()\n",
    "        d_b.zero_grad()\n",
    "        g_ab.zero_grad()\n",
    "        g_ba.zero_grad()\n",
    "        #remember to detach x_fake before using it to compute the discriminator loss\n",
    "        #otherwise the discriminator loss will backpropagate through the generator as well, which is unnecessary.\n",
    "        #x_fake = x_fake.detach()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Get all images and predictions ready\n",
    "        # Get real a and b images ready\n",
    "        real_a = a.to(device)\n",
    "        real_b = b.to(device)\n",
    "\n",
    "        # Get real/fake prediction from discriminator\n",
    "        pred_a = d_a(real_a)\n",
    "        pred_b = d_b(real_b)\n",
    "\n",
    "        # Construct fake images\n",
    "        fake_a = g_ba(real_b)\n",
    "        fake_b = g_ab(real_a)\n",
    "\n",
    "        # Images for cycle consistency loss\n",
    "        cyclic_a = g_ba(fake_a)\n",
    "        cyclic_b = g_ab(fake_b)\n",
    "\n",
    "        # Use discriminator to predict on fake images\n",
    "        pred_a_fake = d_a(fake_a)\n",
    "        pred_b_fake = d_b(fake_b)\n",
    "\n",
    "\n",
    "        # Find losses for each model\n",
    "        # Discriminator loss\n",
    "        loss1 = nn.L1Loss()\n",
    "        fake_labels = torch.zeros(pred_a.size(0)).unsqueeze(1).float().to(device)\n",
    "        real_labels = torch.ones(pred_b.size(0)).unsqueeze(1).float().to(device)\n",
    "        d_a_loss = (loss1(pred_a, real_labels) + loss1(pred_a_fake, fake_labels))/2  # This line might have to have a structure like fake_labels and real_labels at the bottom of the page\n",
    "        d_b_loss = (loss1(pred_b, real_labels) + loss1(pred_b_fake, fake_labels))/2 # This line might have to have a structure like fake_labels and real_labels at the bottom of the page\n",
    "\n",
    "        # Generator loss\n",
    "        loss2 = nn.BCEWithLogitsLoss()\n",
    "        cyclic_loss = (real_a - cyclic_a) + (real_b + cyclic_b)\n",
    "        g_ba_loss = loss2(pred_a_fake, real_labels) + 10 * cyclic_loss\n",
    "        g_ab_loss = loss2(pred_b_fake, real_labels) + 10 * cyclic_loss\n",
    "\n",
    "        \n",
    "        # Update models\n",
    "        d_a_loss.backward(retain_graph=True)\n",
    "        d_a_opt.step()\n",
    "        \n",
    "        d_b_loss.backward(retain_graph=True)\n",
    "        d_b_opt.step()\n",
    "\n",
    "        g_ba_loss.backward(retain_graph=True)\n",
    "        g_ba_opt.step()\n",
    "\n",
    "        g_ab_loss.backward(retain_graph=True)\n",
    "        g_ab_opt.step()\n",
    "\n",
    "        assert(not np.isnan(d_loss.item()))\n",
    "        #Plot results every 100 minibatches\n",
    "        if minibatch_no % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                P = discriminator_final_layer(d(x_fake))\n",
    "                for k in range(11):\n",
    "                    x_fake_k = x_fake[k].cpu().squeeze()/2+.5\n",
    "                    subplots[k].imshow(x_fake_k, cmap='gray')\n",
    "                    subplots[k].set_title('d(x)=%.2f' % P[k])\n",
    "                    subplots[k].axis('off')\n",
    "                z = torch.randn(batch_size, 100).to(device)\n",
    "                H1 = discriminator_final_layer(d(g(z))).cpu()\n",
    "                H2 = discriminator_final_layer(d(x_real)).cpu()\n",
    "                plot_min = min(H1.min(), H2.min()).item()\n",
    "                plot_max = max(H1.max(), H2.max()).item()\n",
    "                subplots[-1].cla()\n",
    "                subplots[-1].hist(H1.squeeze(), label='fake', range=(plot_min, plot_max), alpha=0.5)\n",
    "                subplots[-1].hist(H2.squeeze(), label='real', range=(plot_min, plot_max), alpha=0.5)\n",
    "                subplots[-1].legend()\n",
    "                subplots[-1].set_xlabel('Probability of being real')\n",
    "                subplots[-1].set_title('Discriminator loss: %.2f' % d_loss.item())\n",
    "                \n",
    "                title = 'Epoch {e} - minibatch {n}/{d}'.format(e=epoch+1, n=minibatch_no, d=len(train_loader))\n",
    "                plt.gcf().suptitle(title, fontsize=20)\n",
    "                display.display(plt.gcf())\n",
    "                display.clear_output(wait=True)\n",
    "                \n",
    "\n",
    "#         fake_labels = torch.zeros(d_fake.size(0)).unsqueeze(1).float().to(device)\n",
    "#         real_labels = torch.ones(d_real.size(0)).unsqueeze(1).float().to(device)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-effcb78726d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Construct fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mfake_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_ba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mfake_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_ab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c11640505814>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# class Generator(nn.Module):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c11640505814>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.17 GiB total capacity; 10.65 GiB already allocated; 17.81 MiB free; 10.71 GiB reserved in total by PyTorch)"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825
    },
    "id": "0W4od32oDJ6E",
    "outputId": "2d6c8cf4-6eea-466a-8ed5-2e68b9d54c2b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "############################################################################################\n",
    "#### CODE BEFORE IMPLEMENTING https://hardikbansal.github.io/CycleGANBlog/ ARCHITECTURE ####\n",
    "############################################################################################\n",
    "\n",
    "# #Initialize networks\n",
    "# d_a = Discriminator().to(device)\n",
    "# d_b = Discriminator().to(device)\n",
    "# g_ab = Generator().to(device)\n",
    "# g_ba = Generator().to(device)\n",
    "# d_opt = torch.optim.Adam(d.parameters(), 0.0004, (0.5, 0.999))\n",
    "# g_opt = torch.optim.Adam(g.parameters(), 0.0001, (0.5, 0.999))\n",
    "\n",
    "# plt.figure(figsize=(20,10))\n",
    "# subplots = [plt.subplot(2, 6, k+1) for k in range(12)]\n",
    "# num_epochs = 10\n",
    "# discriminator_final_layer = torch.sigmoid\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for minibatch_no, (x, target) in enumerate(train_loader):\n",
    "#         x_real = x.to(device)*2-1 #scale to (-1, 1) range\n",
    "#         z = torch.randn(x.shape[0], 100).to(device)\n",
    "#         x_fake = g_ab(z)\n",
    "\n",
    "#         #Update discriminator A\n",
    "#         d.zero_grad()\n",
    "#         #remember to detach x_fake before using it to compute the discriminator loss\n",
    "#         #otherwise the discriminator loss will backpropagate through the generator as well, which is unnecessary.\n",
    "#         #x_fake = x_fake.detach()\n",
    "#         loss1 = nn.L1Loss()\n",
    "#         d_fake = d(x_fake)\n",
    "#         d_real = d(x_real)\n",
    "#         fake_labels = torch.zeros(d_fake.size(0)).unsqueeze(1).float().to(device)\n",
    "#         real_labels = torch.ones(d_real.size(0)).unsqueeze(1).float().to(device)\n",
    "#         d_loss = loss1(d_fake, fake_labels) + loss1(d_real, real_labels)\n",
    "#         d_loss.backward(retain_graph=True)\n",
    "#         d_opt.step()\n",
    "\n",
    "#         #Update discriminator B\n",
    "#         #### FORMULA ####\n",
    "#         #model.zero_grad()\n",
    "#         #loss_function = loss_function()\n",
    "#         #model_loss = loss_function(value, target)\n",
    "#         #model_loss.backward(retain_graph = True)\n",
    "#         #model_opt.step()\n",
    "\n",
    "#         #Update generator A\n",
    "#         g.zero_grad()\n",
    "#         #loss = nn.L1Loss()\n",
    "#         loss2 = nn.BCEWithLogitsLoss()\n",
    "#         g_loss = loss2(d(x_fake), real_labels)\n",
    "#         g_loss.backward(retain_graph=True)\n",
    "#         g_opt.step()\n",
    "        \n",
    "\n",
    "#         #Update generator B\n",
    "#         #### FORMULA ####\n",
    "#         #model.zero_grad()\n",
    "#         #loss_function = loss_function()\n",
    "#         #model_loss = loss_function(value, target)\n",
    "#         #model_loss.backward(retain_graph = True)\n",
    "#         #model_opt.step()\n",
    "\n",
    "#         assert(not np.isnan(d_loss.item()))\n",
    "#         #Plot results every 100 minibatches\n",
    "#         if minibatch_no % 100 == 0:\n",
    "#             with torch.no_grad():\n",
    "#                 P = discriminator_final_layer(d(x_fake))\n",
    "#                 for k in range(11):\n",
    "#                     x_fake_k = x_fake[k].cpu().squeeze()/2+.5\n",
    "#                     subplots[k].imshow(x_fake_k, cmap='gray')\n",
    "#                     subplots[k].set_title('d(x)=%.2f' % P[k])\n",
    "#                     subplots[k].axis('off')\n",
    "#                 z = torch.randn(batch_size, 100).to(device)\n",
    "#                 H1 = discriminator_final_layer(d(g(z))).cpu()\n",
    "#                 H2 = discriminator_final_layer(d(x_real)).cpu()\n",
    "#                 plot_min = min(H1.min(), H2.min()).item()\n",
    "#                 plot_max = max(H1.max(), H2.max()).item()\n",
    "#                 subplots[-1].cla()\n",
    "#                 subplots[-1].hist(H1.squeeze(), label='fake', range=(plot_min, plot_max), alpha=0.5)\n",
    "#                 subplots[-1].hist(H2.squeeze(), label='real', range=(plot_min, plot_max), alpha=0.5)\n",
    "#                 subplots[-1].legend()\n",
    "#                 subplots[-1].set_xlabel('Probability of being real')\n",
    "#                 subplots[-1].set_title('Discriminator loss: %.2f' % d_loss.item())\n",
    "                \n",
    "#                 title = 'Epoch {e} - minibatch {n}/{d}'.format(e=epoch+1, n=minibatch_no, d=len(train_loader))\n",
    "#                 plt.gcf().suptitle(title, fontsize=20)\n",
    "#                 display.display(plt.gcf())\n",
    "#                 display.clear_output(wait=True)\n",
    "                "
   ],
   "outputs": [],
   "metadata": {
    "id": "g4ulQjBpelEj"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}